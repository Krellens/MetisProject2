{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = []\n",
    "for i in range(1,50):\n",
    "    url ='https://www.boxofficemojo.com/alltime/domestic.htm?page={}&p=.htm'.format(i)\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    for j in range(4,100): #4 to 100 seems to work\n",
    "        link_list.append('https://www.boxofficemojo.com' + soup.find('div', id ='body').find_all('table')[3].find_all('tr')[j].find('a').get('href'))\n",
    "      \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_info = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Web Scraper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_cleaner(str2clean):\n",
    "    if '<a>' in str2clean:\n",
    "        str2clean = str2clean.replace('<a>','')\n",
    "    if '</a>' in str2clean:\n",
    "        str2clean = str2clean.replace('</a>','')\n",
    "    if '<b>' in str2clean:\n",
    "        str2clean = str2clean.replace('<b>','')\n",
    "    if '</b>' in str2clean:\n",
    "        str2clean = str2clean.replace('</b>','')\n",
    "    if '<td>' in str2clean:\n",
    "        str2clean = str2clean.replace('<td>','')\n",
    "    if '</td>' in str2clean:\n",
    "        str2clean = str2clean.replace('</td>','')    \n",
    "    return str2clean\n",
    "\n",
    "\n",
    "def box_office_mojo_scraper(url,mv_info):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    title = soup.find('title').text.split('(')[0]\n",
    "\n",
    "\n",
    "    try:\n",
    "        budget = str(soup.find(text=re.compile('Production Budget')).findNextSibling())\n",
    "        budget = html_cleaner(budget)\n",
    "        budget = budget.replace('$','')\n",
    "        budget = budget.split()\n",
    "        if budget[1] == 'billion':\n",
    "            budget[1] = '000000000'\n",
    "            budget = ''.join(budget)\n",
    "        if budget[1] == 'million':\n",
    "            budget[1] = '000000'\n",
    "            budget = ''.join(budget)\n",
    "        if budget[1] == 'thousand':\n",
    "            budget[1] = '000'\n",
    "            budget = ''.join(budget)\n",
    "        mv_info[title]['budget'] = int(budget)\n",
    "    except:\n",
    "        mv_info[title]['budget'] = np.nan\n",
    "\n",
    "    #**Pull Genre with RegEx**\n",
    "\n",
    "    try:\n",
    "        genre = str(soup.find(text=re.compile('Genre:')).findNextSibling())\n",
    "        genre = html_cleaner(genre)\n",
    "        mv_info[title]['genre'] = genre\n",
    "    except:\n",
    "        mv_info[title]['genre'] = np.nan\n",
    "\n",
    "    #**Pull Distributor with RegEx**\n",
    "\n",
    "    try:\n",
    "        distributor = str(soup.find(text=re.compile('Distributor:')).findNextSibling())\n",
    "        distributor = html_cleaner(distributor)\n",
    "        distributor = distributor.split('>')[1]\n",
    "        mv_info[title]['distributor'] = distributor\n",
    "    except:\n",
    "        mv_info[title]['distributor'] = np.nan\n",
    "\n",
    "    #**Pull Director**\n",
    "\n",
    "    try:\n",
    "        director_orig = str(soup.find_all(class_='mp_box_content')[2].find_all('td')[1])\n",
    "        director = director_orig.split('>')[3]\n",
    "        if director ==  '</td':\n",
    "            director = director_orig.split('>')[2]\n",
    "            director = director.replace('</font','')\n",
    "        director = director.replace('</a','')\n",
    "        mv_info[title]['director'] = director\n",
    "    except:\n",
    "        mv_info[title]['director'] = np.nan\n",
    "\n",
    "    #**Pull Release Date with RegEx**\n",
    "\n",
    "    try:\n",
    "        release_date = str(soup.find(text=re.compile('Release Date')).findNextSibling())\n",
    "        release_date = release_date.split('>')[3]\n",
    "        release_date = release_date.replace('</a','')\n",
    "        release_date = datetime.strptime(release_date, '%B %d, %Y')\n",
    "        release_date = release_date.strftime('%d %m %Y')\n",
    "        mv_info[title]['release_date'] = release_date\n",
    "    except:\n",
    "        mv_info[title]['release_date'] = np.nan\n",
    "        \n",
    "     #**Pull close date**   \n",
    "    try:\n",
    "        close_date = soup.find_all(class_='mp_box')[1].find(class_='mp_box_content').find_all('tr')[5].find_all('td')[1]\n",
    "        close_date = html_cleaner(str(close_date))\n",
    "        close_date = close_date[1:]\n",
    "        close_date = datetime.strptime(close_date, '%B %d, %Y')\n",
    "        mv_info[title]['close_date'] = close_date.strftime('%d %m %Y')\n",
    "    except:\n",
    "        mv_info[title]['close_date'] = np.nan\n",
    "    \n",
    "    #**pull days in release**\n",
    "    try:\n",
    "        days_in_release = soup.find_all(class_='mp_box')[1].find(class_='mp_box_content').find_all('table')[3]\n",
    "        days_in_release = str(days_in_release).split()[8]\n",
    "        mv_info[title]['days_in_release'] = int(days_in_release)\n",
    "    \n",
    "    except:\n",
    "        mv_info[title]['days_in_release'] = np.nan\n",
    "        \n",
    "        \n",
    "\n",
    "    #**Pull Runtime with RegEx**\n",
    "\n",
    "    try:\n",
    "        runtime_orig = str(soup.find(text=re.compile('Runtime')).findNextSibling())    \n",
    "        runtime_orig = html_cleaner(runtime_orig)\n",
    "        runtime = runtime_orig.split()\n",
    "        runtime = int(runtime[0]) * 60 + int(runtime[2])\n",
    "        mv_info[title]['runtime'] = runtime\n",
    "    except:\n",
    "        runtime = np.nan\n",
    "    \n",
    "\n",
    "    #**Pull Rating with RegEx**\n",
    "\n",
    "    try:\n",
    "        rating = str(soup.find(text=re.compile('MPAA Rating:')).findNextSibling())\n",
    "        rating = html_cleaner(rating)\n",
    "        mv_info[title]['rating'] = rating\n",
    "    except:\n",
    "        mv_info[title]['rating'] = np.nan\n",
    "\n",
    "    #**Pull gross domestic from class mp_box_contet**\n",
    "\n",
    "    try:\n",
    "        gross_domestic = soup.find(class_='mp_box_content').find_all('td')[1].text.split('$')[1] \n",
    "        gross_domestic = int(gross_domestic.replace(',',''))\n",
    "        mv_info[title][\"domestic\"] = gross_domestic\n",
    "    except:\n",
    "        mv_info[title][\"domestic\"] = np.nan\n",
    "      \n",
    "    #**Pull % gross domestic \n",
    "    try:\n",
    "        prcnt_domstc = soup.find(class_='mp_box_content').find_all('td')[2].text\n",
    "        prcnt_domstc = prcnt_domstc.split()[0]\n",
    "        prcnt_domstc = float(prcnt_domstc.replace('%',''))\n",
    "        mv_info[title]['percent_domestic'] = prcnt_domstc\n",
    "    except:\n",
    "        mv_info[title][\"percent_domestic\"] = np.nan\n",
    "\n",
    "    #**Pull foreign from class mp_box_content**\n",
    "\n",
    "    try:    \n",
    "        frgn = soup.find(class_='mp_box_content').find_all('td')[4].text.split('$')[1]\n",
    "        frgn = frgn.replace(',','')\n",
    "        mv_info[title][\"foreign\"] = int(frgn)\n",
    "    except:\n",
    "        mv_info[title][\"foreign\"] = np.nan\n",
    "        \n",
    "    #**Pull % gross foreign\n",
    "    try:    \n",
    "        prcnt_frgn = soup.find(class_='mp_box_content').find_all('td')[5].text\n",
    "        prcnt_frgn = prcnt_frgn.split()[0]\n",
    "        prcnt_frgn = float(prcnt_frgn.replace('%',''))\n",
    "        mv_info[title][\"percent_foreign\"] = prcnt_frgn\n",
    "    except:\n",
    "        mv_info[title][\"percent_foreign\"] = np.nan\n",
    "\n",
    "    #**Pull Opening Weekend from second mp_box class**\n",
    "\n",
    "    try:\n",
    "        open_wknd = soup.find_all(class_='mp_box')[1].find(class_='mp_box_content').find('tr').text.split('$')[1]\n",
    "        open_wknd = open_wknd.replace(',','')\n",
    "        mv_info[title][\"open_wknd\"] = int(open_wknd)\n",
    "    except:\n",
    "        mv_info[title][\"open_wknd\"] = np.nan  \n",
    "        \n",
    "        \n",
    "   #**Pull % total domestic drawn in open wknd\n",
    "    try:\n",
    "        prcnt_wknd = soup.find_all(class_='mp_box')[1].find(class_='mp_box_content').find_all('tr')[2].text.split()\n",
    "        prcnt_wknd = prcnt_wknd[4].replace('%','')\n",
    "        prcnt_wknd = float(prcnt_wknd)\n",
    "        mv_info[title]['prcnt_dom_wknd'] = prcnt_wknd\n",
    "    except:\n",
    "        mv_info[title]['prcnt_dom_wknd'] = np.nan\n",
    "        \n",
    "\n",
    "    #**Pull Theater Rank, # of theaters and avg money per theater from second mp_box class** \n",
    "\n",
    "    try:\n",
    "        thtr_info = soup.find_all(class_='mp_box')[1].find(class_='mp_box_content').find_all('tr')[1].text\n",
    "        thtr_info = thtr_info.split(\" \") #split thtr info into list of strings seperated by ' '\n",
    "\n",
    "        thtr_rank = int(thtr_info[0].split('#')[1]) #take thtr_info, split at hashtag, take second element, convert to int\n",
    "        mv_info[title][\"rank\"] = thtr_rank #add thtr rank to dict\n",
    "\n",
    "        num_thtr = thtr_info[2] #rank is useless without the number of theaters its ranked relative to, so take that as well\n",
    "        num_thtr = thtr_info[2].replace(',','')\n",
    "        mv_info[title][\"numbr_thtr\"] = int(num_thtr) #add number of theaters to dict\n",
    "\n",
    "        avg_per_thtr = thtr_info[4].replace(',','',) #remove comma from avg $ per thtr\n",
    "        avg_per_thtr = int(avg_per_thtr.replace('$','')) #remove $, convert to int\n",
    "        mv_info[title][\"avg_per_thtr\"] = avg_per_thtr #add avg_per_thtr to dict\n",
    "\n",
    "    except:\n",
    "        mv_info[title][\"rank\"] = np.nan\n",
    "        mv_info[title][\"numbr_thtr\"] = np.nan\n",
    "        mv_info[title][\"avg_per_thtr\"] = np.nan\n",
    "\n",
    "    #**Pull widest release from second mp_box class and 5th table** \n",
    "\n",
    "    try:\n",
    "        widest_release = soup.find_all(class_='mp_box')[1].find(class_='mp_box_content').find_all('tr')[4].text\n",
    "        widest_release = widest_release.split()[2]\n",
    "        widest_release = int(widest_release.replace(',',''))\n",
    "        mv_info[title][\"wdst_rel\"] = widest_release\n",
    "    except:\n",
    "         mv_info[title][\"wdst_rel\"] = np.nan\n",
    "            \n",
    "    return(mv_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in link_list:\n",
    "    box_office_mojo_scraper(i, mv_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mv_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(mv_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('movie_data', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
